import streamlit as st
import re
import random
import zipfile
import io
import os
from xml.dom import minidom
import pandas as pd

# ==================== PH·∫¶N 1: LOGIC X·ª¨ L√ù (CORE) ====================

W_NS = "http://schemas.openxmlformats.org/wordprocessingml/2006/main"
R_NS = "http://schemas.openxmlformats.org/officeDocument/2006/relationships"

def parse_range_string(s):
    res = set()
    if not s: return res
    parts = str(s).split(',')
    for part in parts:
        part = part.strip()
        if not part: continue
        if '-' in part:
            try:
                start, end = map(int, part.split('-'))
                res.update(range(start, end + 1))
            except: pass
        else:
            try:
                res.add(int(part))
            except: pass
    return res

def escape_xml(text):
    if not text: return ""
    return str(text).replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;").replace('"', "&quot;").replace("'", "&apos;")

def is_correct_option(block):
    """Ki·ªÉm tra xem block (ƒëo·∫°n vƒÉn) c√≥ ch·ª©a d·∫•u hi·ªáu ƒë√°p √°n ƒë√∫ng kh√¥ng (g·∫°ch ch√¢n ho·∫∑c ƒë·ªè)"""
    r_nodes = block.getElementsByTagNameNS(W_NS, "r")
    for r in r_nodes:
        # Ki·ªÉm tra g·∫°ch ch√¢n
        rPr_list = r.getElementsByTagNameNS(W_NS, "rPr")
        for rPr in rPr_list:
            u_list = rPr.getElementsByTagNameNS(W_NS, "u")
            if u_list:
                val = u_list[0].getAttributeNS(W_NS, "val")
                if val and val != "none": return True
            
            # Ki·ªÉm tra m√†u ƒë·ªè
            color_list = rPr.getElementsByTagNameNS(W_NS, "color")
            if color_list:
                val = color_list[0].getAttributeNS(W_NS, "val")
                # C√°c m√£ m√†u ƒë·ªè th∆∞·ªùng g·∫∑p trong Word
                if val and val.upper() in ["FF0000", "RED", "C00000", "FF3333"]: return True
    return False

def extract_short_answer_key(question_blocks):
    key = ""
    clean_blocks = []
    for block in question_blocks:
        txt = get_text(block)
        m = re.match(r'^\s*(?:ƒê√°p √°n|DA|L·ªùi gi·∫£i|HD|H∆∞·ªõng d·∫´n)\s*[:\.]?\s*(.*)', txt, re.IGNORECASE)
        if m:
            key = m.group(1).strip()
            continue
        clean_blocks.append(block)
    return clean_blocks, key

def get_text(block):
    texts = []
    t_nodes = block.getElementsByTagNameNS(W_NS, "t")
    for t in t_nodes:
        if t.firstChild and t.firstChild.nodeValue:
            texts.append(t.firstChild.nodeValue)
    return "".join(texts).strip()

# --- AUTO-SPLIT MERGED OPTIONS LOGIC ---

def split_paragraph_at_text_index(p, split_idx):
    """Chia paragraph p th√†nh 2 paragraph t·∫°i v·ªã tr√≠ text index"""
    doc = p.ownerDocument
    
    # 1. Map to√†n b·ªô text node v√† v·ªã tr√≠ c·ªßa n√≥
    t_nodes = []
    curr_len = 0
    
    def walk_t_nodes(node):
        nonlocal curr_len
        if node.nodeType == node.ELEMENT_NODE and node.localName == 't' and node.namespaceURI == W_NS:
            txt = node.firstChild.nodeValue if node.firstChild else ""
            t_nodes.append({
                "node": node,
                "start": curr_len,
                "end": curr_len + len(txt),
                "text": txt,
                "parent_run": node.parentNode
            })
            curr_len += len(txt)
        elif node.hasChildNodes():
            for child in node.childNodes:
                walk_t_nodes(child)
                
    walk_t_nodes(p)
    
    if split_idx <= 0 or split_idx >= curr_len:
        return None # Kh√¥ng c·∫ßn split

    # T√¨m node ch·ª©a ƒëi·ªÉm c·∫Øt
    target_info = None
    for info in t_nodes:
        if info["start"] <= split_idx < info["end"]:
            target_info = info
            break
            
    if not target_info: return None
    
    # 2. Clone paragraph m·ªõi
    p_new = p.cloneNode(True)
    p.parentNode.insertBefore(p_new, p.nextSibling)
    
    # 3. X·ª≠ l√Ω P c≈© (Gi·ªØ ph·∫ßn ƒë·∫ßu, x√≥a ph·∫ßn sau)
    # C·∫ßn x√°c ƒë·ªãnh node c·∫Øt trong P c≈© ƒë·ªÉ x√≥a c√°c node sau n√≥
    # Logic ƒë∆°n gi·∫£n h√≥a: Duy·ªát l·∫°i t_nodes c·ªßa P c≈©, c·∫Øt text t·∫°i target, x√≥a c√°c t_node sau target
    # Tuy nhi√™n c·∫•u tr√∫c DOM ph·ª©c t·∫°p (Run > Text). 
    
    # Gi·∫£i ph√°p an to√†n h∆°n: 
    # - P c≈©: C·∫Øt text t·∫°i split_point. X√≥a n·ªôi dung text sau ƒë√≥. (C√°c run sau ƒë√≥ s·∫Ω r·ªóng text, nh∆∞ng v·∫´n c√≤n style -> ch·∫•p nh·∫≠n ƒë∆∞·ª£c ho·∫∑c cleanup sau)
    # - P m·ªõi: C·∫Øt text t·∫°i split_point (l·∫•y ph·∫ßn sau). X√≥a n·ªôi dung text tr∆∞·ªõc ƒë√≥.
    
    # X·ª≠ l√Ω P c≈© (Left)
    rel_idx = split_idx - target_info["start"]
    target_info["node"].firstChild.nodeValue = target_info["text"][:rel_idx] # C·∫Øt text
    
    # X√≥a n·ªôi dung c·ªßa c√°c text node SAU node c·∫Øt trong P c≈©
    found_split = False
    
    def clear_text_after(node, stop_node):
        nonlocal found_split
        if node == stop_node:
            found_split = True
            return
        
        if node.nodeType == node.ELEMENT_NODE and node.localName == 't' and node.namespaceURI == W_NS:
            if found_split:
                if node.firstChild: node.firstChild.nodeValue = ""
        
        if node.hasChildNodes():
            for child in node.childNodes:
                clear_text_after(child, stop_node)
                
    clear_text_after(p, target_info["node"])
    
    # X·ª≠ l√Ω P m·ªõi (Right)
    # T√¨m l·∫°i node t∆∞∆°ng ·ª©ng trong P m·ªõi (do cloneNode)
    # V√¨ clone ho√†n to√†n n√™n c·∫•u tr√∫c y h·ªát. Ta duy·ªát t∆∞∆°ng t·ª± ƒë·ªÉ t√¨m node ƒë·ªëi ·ª©ng.
    
    t_nodes_new = []
    def walk_t_nodes_new(node):
        if node.nodeType == node.ELEMENT_NODE and node.localName == 't' and node.namespaceURI == W_NS:
            t_nodes_new.append(node)
        elif node.hasChildNodes():
            for child in node.childNodes:
                walk_t_nodes_new(child)
    
    walk_t_nodes_new(p_new)
    
    # Index c·ªßa node c·∫Øt trong danh s√°ch t_nodes l√† gi·ªëng nhau
    target_idx_in_list = t_nodes.index(target_info)
    target_t_new = t_nodes_new[target_idx_in_list]
    
    # C·∫Øt text p m·ªõi (L·∫•y ph·∫ßn sau)
    target_t_new.firstChild.nodeValue = target_info["text"][rel_idx:]
    
    # X√≥a n·ªôi dung c√°c text node TR∆Ø·ªöC node c·∫Øt trong P m·ªõi
    for i in range(target_idx_in_list):
        t_node = t_nodes_new[i]
        if t_node.firstChild: t_node.firstChild.nodeValue = ""
        
    return p_new

def fix_merged_options(dom):
    """T·ª± ƒë·ªông t√°ch c√°c ƒë√°p √°n A. B. C. D. n·∫±m chung 1 d√≤ng th√†nh c√°c d√≤ng ri√™ng"""
    body = dom.getElementsByTagNameNS(W_NS, "body")[0]
    blocks = []
    for child in list(body.childNodes):
        if child.nodeType == child.ELEMENT_NODE and child.localName == "p":
            blocks.append(child)
            
    fixed_count = 0
    
    # Regex t√¨m B., C., D. n·∫±m gi·ªØa d√≤ng (c√≥ kho·∫£ng tr·∫Øng ph√≠a tr∆∞·ªõc)
    # Group 1: Whitespace, Group 2: Letter (B-D), Group 3: Dot/Paren
    # VD: " ...  B. "
    pattern = re.compile(r'(\s+)([B-D])([\.\)])')
    
    i = 0
    while i < len(blocks):
        block = blocks[i]
        txt = get_text(block)
        
        # Ch·ªâ x·ª≠ l√Ω n·∫øu d√≤ng n√†y c√≥ v·∫ª l√† d√≤ng ƒë√°p √°n (ch·ª©a A. ho·∫∑c a.)
        if not re.match(r'^\s*[A-Da-d][\.\)]', txt):
            i += 1
            continue
            
        # T√¨m v·ªã tr√≠ c·∫ßn c·∫Øt
        match = pattern.search(txt)
        if match:
            # V·ªã tr√≠ c·∫Øt l√† b·∫Øt ƒë·∫ßu c·ªßa ch·ªØ c√°i (B, C, D)
            # match.start(2) l√† v·ªã tr√≠ c·ªßa k√Ω t·ª± B/C/D
            split_idx = match.start(2)
            
            # Th·ª±c hi·ªán t√°ch
            new_block = split_paragraph_at_text_index(block, split_idx)
            
            if new_block:
                # Ch√®n block m·ªõi v√†o danh s√°ch ƒë·ªÉ duy·ªát ti·∫øp (v√¨ block m·ªõi c√≥ th·ªÉ ch·ª©a C, D ti·∫øp)
                blocks.insert(i + 1, new_block)
                fixed_count += 1
                
                # Kh√¥ng tƒÉng i, ƒë·ªÉ v√≤ng l·∫∑p sau ki·ªÉm tra l·∫°i block hi·ªán t·∫°i 
                # (th·ª±c ra block hi·ªán t·∫°i ƒë√£ b·ªã c·∫Øt ng·∫Øn, block m·ªõi n·∫±m sau)
                # Logic ƒë√∫ng: block hi·ªán t·∫°i ƒë√£ m·∫•t ph·∫ßn sau. Block sau (new_block) ch·ª©a ph·∫ßn sau.
                # C·∫ßn ki·ªÉm tra ti·∫øp new_block xem c√≤n C. D. kh√¥ng.
                # N√™n ta tƒÉng i ƒë·ªÉ qua block hi·ªán t·∫°i, x·ª≠ l√Ω block k·∫ø ti·∫øp (new_block)
                i += 1 
            else:
                i += 1
        else:
            i += 1
            
    return fixed_count

# --- END AUTO-SPLIT LOGIC ---

def set_paragraph_tabs(paragraph, tab_positions):
    doc = paragraph.ownerDocument
    pPr_list = paragraph.getElementsByTagNameNS(W_NS, "pPr")
    if not pPr_list:
        pPr = doc.createElementNS(W_NS, "w:pPr")
        paragraph.insertBefore(pPr, paragraph.firstChild)
    else: pPr = pPr_list[0]
    tabs_list = pPr.getElementsByTagNameNS(W_NS, "tabs")
    for tabs in tabs_list: pPr.removeChild(tabs)
    w_tabs = doc.createElementNS(W_NS, "w:tabs")
    for pos in tab_positions:
        w_tab = doc.createElementNS(W_NS, "w:tab")
        w_tab.setAttributeNS(W_NS, "w:val", "left")
        w_tab.setAttributeNS(W_NS, "w:pos", str(pos))
        w_tabs.appendChild(w_tab)
    pPr.appendChild(w_tabs)

def merge_paragraphs(p_dest, p_src):
    doc = p_dest.ownerDocument
    r_tab = doc.createElementNS(W_NS, "w:r")
    tab = doc.createElementNS(W_NS, "w:tab")
    r_tab.appendChild(tab)
    p_dest.appendChild(r_tab)
    children = []
    for child in p_src.childNodes:
        if child.localName not in ["pPr", "proofErr", "bookmarkStart", "bookmarkEnd"]:
            children.append(child)
    for child in children: p_dest.appendChild(child)
    return p_dest

def format_mcq_layout(question_blocks):
    option_indices = []
    for i, block in enumerate(question_blocks):
        if re.match(r'^\s*[A-D][\.\)]', get_text(block), re.IGNORECASE):
            option_indices.append(i)
    if len(option_indices) != 4: return question_blocks
    opt_blocks = [question_blocks[i] for i in option_indices]
    lengths = [len(get_text(b)) for b in opt_blocks]
    max_len = max(lengths)
    layout_mode = 1
    if max_len < 20: layout_mode = 4
    elif max_len < 45: layout_mode = 2
    else: layout_mode = 1
    if layout_mode == 1: return question_blocks
    new_question_blocks = []
    for i in range(option_indices[0]): new_question_blocks.append(question_blocks[i])
    if layout_mode == 4:
        p_root = opt_blocks[0]
        merge_paragraphs(p_root, opt_blocks[1])
        merge_paragraphs(p_root, opt_blocks[2])
        merge_paragraphs(p_root, opt_blocks[3])
        set_paragraph_tabs(p_root, [3000, 6000, 9000])
        new_question_blocks.append(p_root)
    elif layout_mode == 2:
        row1 = opt_blocks[0]
        merge_paragraphs(row1, opt_blocks[1])
        set_paragraph_tabs(row1, [6000])
        new_question_blocks.append(row1)
        row2 = opt_blocks[2]
        merge_paragraphs(row2, opt_blocks[3])
        set_paragraph_tabs(row2, [6000])
        new_question_blocks.append(row2)
    last_opt_idx = option_indices[-1]
    for i in range(last_opt_idx + 1, len(question_blocks)): new_question_blocks.append(question_blocks[i])
    return new_question_blocks

def style_run_blue_bold(run):
    doc = run.ownerDocument
    rPr_list = run.getElementsByTagNameNS(W_NS, "rPr")
    if rPr_list: rPr = rPr_list[0]
    else:
        rPr = doc.createElementNS(W_NS, "w:rPr")
        run.insertBefore(rPr, run.firstChild)
    color_list = rPr.getElementsByTagNameNS(W_NS, "color")
    if color_list: color_el = color_list[0]
    else:
        color_el = doc.createElementNS(W_NS, "w:color")
        rPr.appendChild(color_el)
    color_el.setAttributeNS(W_NS, "w:val", "0000FF")
    b_list = rPr.getElementsByTagNameNS(W_NS, "b")
    if not b_list:
        b_el = doc.createElementNS(W_NS, "w:b")
        rPr.appendChild(b_el)

def update_mcq_label(paragraph, new_label):
    t_nodes = paragraph.getElementsByTagNameNS(W_NS, "t")
    if not t_nodes: return
    new_letter = new_label[0].upper()
    for i, t in enumerate(t_nodes):
        if not t.firstChild: continue
        txt = t.firstChild.nodeValue
        m = re.match(r'^(\s*)([A-D])([\.\)])?', txt, re.IGNORECASE)
        if not m: continue
        leading_space = m.group(1) or ""
        old_punct = m.group(3) or ""
        after_match = txt[m.end():]
        t.firstChild.nodeValue = leading_space + new_letter + ("." if not old_punct else old_punct) + " " + after_match.strip()
        run = t.parentNode
        if run and run.localName == "r": style_run_blue_bold(run)
        for j in range(i + 1, len(t_nodes)):
            t2 = t_nodes[j]
            if not t2.firstChild: continue
            val2 = t2.firstChild.nodeValue
            if re.match(r'^[\s\.]+$', val2): t2.firstChild.nodeValue = ""
            elif re.match(r'^\.', val2): 
                t2.firstChild.nodeValue = val2[1:]
                break
            else: break
        break

def update_tf_label(paragraph, new_label):
    t_nodes = paragraph.getElementsByTagNameNS(W_NS, "t")
    if not t_nodes: return
    new_letter = new_label[0].lower()
    for i, t in enumerate(t_nodes):
        if not t.firstChild: continue
        txt = t.firstChild.nodeValue
        m = re.match(r'^(\s*)([a-d])(\))?', txt, re.IGNORECASE)
        if not m: continue
        leading_space = m.group(1) or ""
        after_match = txt[m.end():]
        t.firstChild.nodeValue = leading_space + new_letter + ")" + after_match
        run = t.parentNode
        if run and run.localName == "r": style_run_blue_bold(run)
        for j in range(i + 1, len(t_nodes)):
            t2 = t_nodes[j]
            if not t2.firstChild: continue
            val2 = t2.firstChild.nodeValue
            if re.match(r'^[\s\)]+$', val2): t2.firstChild.nodeValue = ""
            elif re.match(r'^\s*\)', val2):
                t2.firstChild.nodeValue = re.sub(r'^\s*\)', '', val2, count=1)
                break
            else: break
        break

def update_question_label(paragraph, new_label):
    t_nodes = paragraph.getElementsByTagNameNS(W_NS, "t")
    if not t_nodes: return
    for i, t in enumerate(t_nodes):
        if not t.firstChild: continue
        txt = t.firstChild.nodeValue
        m = re.match(r'^(\s*)(C√¢u\s*)(\d+)(\.)?', txt, re.IGNORECASE)
        if not m: continue
        leading_space = m.group(1) or ""
        after_match = txt[m.end():]
        t.firstChild.nodeValue = leading_space + new_label + after_match
        run = t.parentNode
        if run and run.localName == "r": style_run_blue_bold(run)
        for j in range(i + 1, len(t_nodes)):
            t2 = t_nodes[j]
            if not t2.firstChild: continue
            if re.match(r'^[\s0-9\.]*$', t2.firstChild.nodeValue): t2.firstChild.nodeValue = ""
            else: break
        break

def find_part_index(blocks, part_number):
    pattern = re.compile(rf'PH·∫¶N\s*{part_number}\b', re.IGNORECASE)
    for i, block in enumerate(blocks):
        if pattern.search(get_text(block)): return i
    return -1

def parse_questions_in_range(blocks, start, end):
    part_blocks = blocks[start:end]
    items = [] 
    intro = []
    i = 0
    while i < len(part_blocks):
        text = get_text(part_blocks[i])
        if re.match(r'^C√¢u\s*\d+\b', text, re.IGNORECASE): break
        if "@B·∫ÆT ƒê·∫¶U D√ôNG CHUNG@" in text.upper(): break
        intro.append(part_blocks[i])
        i += 1
    while i < len(part_blocks):
        block = part_blocks[i]
        text = get_text(block)
        if "@B·∫ÆT ƒê·∫¶U D√ôNG CHUNG@" in text.upper():
            cluster_header = []
            cluster_questions = []
            i += 1 
            while i < len(part_blocks):
                b_curr = part_blocks[i]
                t_curr = get_text(b_curr)
                if "@K·∫æT TH√öC D√ôNG CHUNG@" in t_curr.upper():
                    i += 1 
                    break
                if re.match(r'^C√¢u\s*\d+\b', t_curr, re.IGNORECASE):
                    one_q = [b_curr]
                    i += 1
                    while i < len(part_blocks):
                        b_next = part_blocks[i]
                        t_next = get_text(b_next)
                        if "@K·∫æT TH√öC D√ôNG CHUNG@" in t_next.upper(): break
                        if re.match(r'^C√¢u\s*\d+\b', t_next, re.IGNORECASE): break
                        one_q.append(b_next)
                        i += 1
                    cluster_questions.append(one_q)
                else:
                    if cluster_questions: cluster_questions[-1].append(b_curr)
                    else: cluster_header.append(b_curr)
                    i += 1
            items.append({"type": "cluster", "header": cluster_header, "questions": cluster_questions})
            continue
        if re.match(r'^C√¢u\s*\d+\b', text, re.IGNORECASE):
            group = [block]
            i += 1
            while i < len(part_blocks):
                t2 = get_text(part_blocks[i])
                if re.match(r'^C√¢u\s*\d+\b', t2, re.IGNORECASE): break
                if "@B·∫ÆT ƒê·∫¶U D√ôNG CHUNG@" in t2.upper(): break
                if re.match(r'^PH·∫¶N\s*\d\b', t2, re.IGNORECASE): break
                group.append(part_blocks[i])
                i += 1
            items.append({"type": "question", "blocks": group})
        else:
            if items and items[-1]["type"] == "question": items[-1]["blocks"].append(block)
            elif not items: intro.append(block)
            i += 1
    return intro, items

def shuffle_array(arr):
    out = arr.copy()
    for i in range(len(out) - 1, 0, -1):
        j = random.randint(0, i)
        out[i], out[j] = out[j], out[i]
    return out

# --- NEW: VALIDATION FUNCTION WITH AUTO-FIX ---
def check_exam_structure(file_bytes):
    """Ki·ªÉm tra c·∫•u tr√∫c ƒë·ªÅ (Ph·∫ßn 1) tr∆∞·ªõc khi tr·ªôn, c√≥ t·ª± ƒë·ªông s·ª≠a d√≤ng"""
    input_buffer = io.BytesIO(file_bytes)
    messages = []
    is_valid = True
    
    try:
        with zipfile.ZipFile(input_buffer, 'r') as zin:
            doc_xml = zin.read("word/document.xml").decode('utf-8')
            dom = minidom.parseString(doc_xml)
            
            # 1. AUTO FIX: T√°ch c√°c ƒë√°p √°n d√≠nh li·ªÅn
            fixed_cnt = fix_merged_options(dom)
            if fixed_cnt > 0:
                messages.append(f"‚úÖ ƒê√£ t·ª± ƒë·ªông t√°ch {fixed_cnt} d√≤ng ƒë√°p √°n b·ªã d√≠nh li·ªÅn.")
            
            body = dom.getElementsByTagNameNS(W_NS, "body")[0]
            blocks = []
            for child in list(body.childNodes):
                if child.nodeType == child.ELEMENT_NODE and child.localName in ["p", "tbl"]:
                    blocks.append(child)
            
            # T√¨m ph·∫ßn 1
            p1 = find_part_index(blocks, 1)
            p2 = find_part_index(blocks, 2)
            
            start = 0
            end = len(blocks)
            
            if p1 >= 0:
                start = p1 + 1
                if p2 >= 0: end = p2
            elif p2 >= 0:
                end = p2
            
            _, items = parse_questions_in_range(blocks, start, end)
            
            if not items:
                messages.append("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c√¢u h·ªèi tr·∫Øc nghi·ªám n√†o (Ph·∫ßn 1). H√£y ki·ªÉm tra l·∫°i t·ª´ kh√≥a 'C√¢u ...'.")
                return False, messages

            q_count = 0
            for item in items:
                if item["type"] == "question":
                    q_count += 1
                    q_blocks = item["blocks"]
                    
                    # 1. Ki·ªÉm tra s·ªë l∆∞·ª£ng ƒë√°p √°n
                    opt_blocks = []
                    correct_count = 0
                    
                    q_text_header = get_text(q_blocks[0])
                    
                    for b in q_blocks:
                        txt = get_text(b)
                        if re.match(r'^\s*[A-D][\.\)]', txt, re.IGNORECASE):
                            opt_blocks.append(b)
                            if is_correct_option(b):
                                correct_count += 1
                    
                    # C·∫£nh b√°o n·∫øu kh√¥ng ƒë·ªß 4 ƒë√°p √°n
                    if len(opt_blocks) < 4:
                        is_valid = False
                        messages.append(f"‚ùå {q_text_header[:10]}...: Ch·ªâ t√¨m th·∫•y {len(opt_blocks)} ƒë√°p √°n (A,B,C,D). C√≥ th·ªÉ do ƒë·ªãnh d·∫°ng tab ch∆∞a chu·∫©n.")
                    
                    # 2. Ki·ªÉm tra ƒë√°p √°n ƒë√∫ng
                    if correct_count == 0:
                        is_valid = False
                        messages.append(f"‚ùå {q_text_header[:10]}...: Ch∆∞a ch·ªçn ƒë√°p √°n ƒë√∫ng (Ch∆∞a g·∫°ch ch√¢n ho·∫∑c t√¥ ƒë·ªè).")
                    elif correct_count > 1:
                        is_valid = False
                        messages.append(f"‚ùå {q_text_header[:10]}...: C√≥ {correct_count} ƒë√°p √°n ƒë∆∞·ª£c ƒë√°nh d·∫•u ƒë√∫ng (Ch·ªâ ƒë∆∞·ª£c ph√©p c√≥ 1).")
                
                elif item["type"] == "cluster":
                     messages.append(f"‚ÑπÔ∏è Ph√°t hi·ªán nh√≥m c√¢u h·ªèi d√πng chung. H·ªá th·ªëng ch∆∞a h·ªó tr·ª£ ki·ªÉm tra chi ti·∫øt b√™n trong nh√≥m n√†y, nh∆∞ng v·∫´n s·∫Ω tr·ªôn b√¨nh th∆∞·ªùng.")

            if q_count == 0:
                 messages.append("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c√¢u h·ªèi n√†o b·∫Øt ƒë·∫ßu b·∫±ng 'C√¢u ...'.")
                 is_valid = False

    except Exception as e:
        return False, [f"L·ªói khi ƒë·ªçc file: {str(e)}"]

    return is_valid, messages

# --- HELPER FUNCTIONS FOR WORD XML GENERATION ---
def create_header_xml(doc, info):
    so_gd = escape_xml(info.get("so_gd", "").upper())
    truong = escape_xml(info.get("truong", ""))
    ky_thi = escape_xml(info.get("ky_thi", "").upper())
    mon_thi = escape_xml(info.get("mon_thi", "").upper())
    thoi_gian = escape_xml(info.get("thoi_gian", ""))
    nam_hoc = escape_xml(info.get("nam_hoc", ""))
    xml_str = f"""
    <w:tbl xmlns:w="{W_NS}">
        <w:tblPr>
            <w:tblW w:w="0" w:type="auto"/>
            <w:jc w:val="center"/>
            <w:tblBorders>
                <w:top w:val="none" w:sz="0" w:space="0" w:color="auto"/>
                <w:left w:val="none" w:sz="0" w:space="0" w:color="auto"/>
                <w:bottom w:val="none" w:sz="0" w:space="0" w:color="auto"/>
                <w:right w:val="none" w:sz="0" w:space="0" w:color="auto"/>
                <w:insideH w:val="none" w:sz="0" w:space="0" w:color="auto"/>
                <w:insideV w:val="none" w:sz="0" w:space="0" w:color="auto"/>
            </w:tblBorders>
        </w:tblPr>
        <w:tr>
            <w:tc>
                <w:tcPr><w:tcW w:w="4500" w:type="dxa"/></w:tcPr>
                <w:p>
                    <w:pPr><w:jc w:val="center"/></w:pPr>
                    <w:r><w:rPr><w:b/></w:rPr><w:t>{so_gd}</w:t></w:r>
                </w:p>
                <w:p>
                    <w:pPr><w:jc w:val="center"/></w:pPr>
                    <w:r><w:rPr><w:b/></w:rPr><w:t>{truong}</w:t></w:r>
                </w:p>
                <w:p>
                    <w:pPr><w:jc w:val="center"/></w:pPr>
                    <w:r><w:t>------------------</w:t></w:r>
                </w:p>
            </w:tc>
            <w:tc>
                <w:tcPr><w:tcW w:w="4500" w:type="dxa"/></w:tcPr>
                <w:p>
                    <w:pPr><w:jc w:val="center"/></w:pPr>
                    <w:r><w:rPr><w:b/></w:rPr><w:t>{ky_thi}</w:t></w:r>
                </w:p>
                <w:p>
                    <w:pPr><w:jc w:val="center"/></w:pPr>
                    <w:r><w:rPr><w:b/></w:rPr><w:t>M√îN: {mon_thi}</w:t></w:r>
                </w:p>
                <w:p>
                    <w:pPr><w:jc w:val="center"/></w:pPr>
                    <w:r><w:t>Th·ªùi gian l√†m b√†i: {thoi_gian}</w:t></w:r>
                </w:p>
                 <w:p>
                    <w:pPr><w:jc w:val="center"/></w:pPr>
                    <w:r><w:t>(NƒÉm h·ªçc: {nam_hoc})</w:t></w:r>
                </w:p>
            </w:tc>
        </w:tr>
    </w:tbl>
    """
    return minidom.parseString(xml_str).documentElement

def create_footer_xml_content(ma_de):
    xml_str = f"""
    <w:ftr xmlns:w="{W_NS}">
        <w:p>
            <w:pPr>
                <w:pStyle w:val="Footer"/>
                <w:jc w:val="right"/>
                <w:pBdr>
                    <w:top w:val="single" w:sz="6" w:space="1" w:color="auto"/>
                </w:pBdr>
            </w:pPr>
            <w:r>
                <w:t xml:space="preserve">M√£ ƒë·ªÅ {ma_de} - Trang </w:t>
            </w:r>
            <w:fldSimple w:instr="PAGE"/>
        </w:p>
    </w:ftr>
    """
    return xml_str.strip()

def add_header_to_body(dom, body, header_info):
    if not header_info.get("enable", False): return
    try:
        tbl_node = create_header_xml(dom, header_info)
        if body.firstChild: body.insertBefore(tbl_node, body.firstChild)
        else: body.appendChild(tbl_node)
        p_empty = dom.createElementNS(W_NS, "w:p")
        if body.childNodes.length > 1: body.insertBefore(p_empty, body.childNodes[1])
    except: pass

def relabel_mcq_options(question_blocks):
    letters = ["A", "B", "C", "D"]
    count = 0
    for block in question_blocks:
        if re.match(r'^\s*[A-D][\.\)]', get_text(block), re.IGNORECASE):
            l = letters[count] if count < 4 else "D"
            update_mcq_label(block, f"{l}.")
            count += 1

def relabel_tf_options(question_blocks):
    letters = ["a", "b", "c", "d"]
    count = 0
    for block in question_blocks:
        if re.match(r'^\s*[a-d]\)', get_text(block), re.IGNORECASE):
            l = letters[count] if count < 4 else "d"
            update_tf_label(block, f"{l})")
            count += 1

def shuffle_mcq_options(question_blocks, allow_shuffle=True):
    indices = []
    correct_indices_before = []
    for i, block in enumerate(question_blocks):
        if re.match(r'^\s*[A-D][\.\)]', get_text(block), re.IGNORECASE):
            indices.append(i)
            if is_correct_option(block): correct_indices_before.append(i)
    if len(indices) < 2: return question_blocks, ""
    options = [question_blocks[idx] for idx in indices]
    perm = list(range(len(options)))
    if allow_shuffle: random.shuffle(perm)
    shuffled_options = [options[p] for p in perm]
    new_correct_char = ""
    if correct_indices_before:
        orig_correct_idx_in_options = -1
        for k, val in enumerate(indices):
            if val == correct_indices_before[0]:
                orig_correct_idx_in_options = k
                break
        if orig_correct_idx_in_options != -1:
            for new_pos, old_pos in enumerate(perm):
                if old_pos == orig_correct_idx_in_options:
                    letters = ["A", "B", "C", "D", "E", "F"]
                    if new_pos < len(letters): new_correct_char = letters[new_pos]
                    break
    min_idx, max_idx = min(indices), max(indices)
    before = question_blocks[:min_idx]
    after = question_blocks[max_idx + 1:]
    return before + shuffled_options + after, new_correct_char

def shuffle_tf_options(question_blocks, allow_shuffle=True):
    option_indices = {}
    for i, block in enumerate(question_blocks):
        m = re.match(r'^\s*([a-d])\)', get_text(block), re.IGNORECASE)
        if m: option_indices[m.group(1).lower()] = i
    abc_idx = [option_indices.get(k) for k in ["a", "b", "c"] if option_indices.get(k) is not None]
    if len(abc_idx) < 2: return question_blocks, ["", "", "", ""]
    abc_nodes = [question_blocks[idx] for idx in abc_idx]
    if allow_shuffle: shuffled_abc = shuffle_array(abc_nodes)
    else: shuffled_abc = abc_nodes.copy()
    all_vals = [v for v in option_indices.values() if v is not None]
    min_idx, max_idx = min(all_vals), max(all_vals)
    before = question_blocks[:min_idx]
    after = question_blocks[max_idx + 1:]
    d_node = question_blocks[option_indices["d"]] if "d" in option_indices else None
    middle = shuffled_abc.copy()
    if d_node: middle.append(d_node)
    current_key_status = []
    for block in middle:
        status = "D" if is_correct_option(block) else "S"
        current_key_status.append(status)
    return before + middle + after, current_key_status

def process_single_question_logic(q, part_type, allow_shuffle_opt):
    new_block = []
    key = ""
    if part_type == "PHAN1":
        new_block, key = shuffle_mcq_options(q, allow_shuffle_opt)
    elif part_type == "PHAN2":
        new_block, key = shuffle_tf_options(q, allow_shuffle_opt)
    elif part_type == "PHAN3":
        new_block, key = extract_short_answer_key(q)
    else:
        new_block = q.copy()
    return new_block, key

def process_part(blocks, start, end, part_type, global_q_idx_start, config):
    intro, items = parse_questions_in_range(blocks, start, end)
    processed_items = []
    current_q_counter = global_q_idx_start
    fixed_pos_set = config.get("fixed_pos_set", set())
    fixed_opt_set = config.get("fixed_opt_set", set())
    fix_group_pos = config.get("fix_group_pos", False)
    
    for item in items:
        if item["type"] == "question":
            q_idx = current_q_counter + 1
            allow_opt = config.get("shuffle_opt_global", True)
            if q_idx in fixed_opt_set: allow_opt = False
            new_q, key = process_single_question_logic(item["blocks"], part_type, allow_opt)
            processed_items.append({"type": "question", "blocks": new_q, "keys": [key], "original_idx": q_idx})
            current_q_counter += 1
        elif item["type"] == "cluster":
            header = item["header"]
            sub_qs = item["questions"]
            sub_items_data = []
            sub_keys = []
            for sub_q_blocks in sub_qs:
                q_idx = current_q_counter + 1
                allow_opt = config.get("shuffle_opt_global", True)
                if q_idx in fixed_opt_set: allow_opt = False
                new_q, key = process_single_question_logic(sub_q_blocks, part_type, allow_opt)
                sub_items_data.append((new_q, key))
                current_q_counter += 1
            if config.get("shuffle_pos_global", True): random.shuffle(sub_items_data)
            cluster_final_blocks = header.copy()
            for sq, k in sub_items_data:
                cluster_final_blocks.extend(sq)
                sub_keys.append(k)
            processed_items.append({
                "type": "cluster",
                "blocks": cluster_final_blocks,
                "keys": sub_keys,
                "original_idx": current_q_counter - len(sub_qs) + 1 
            })

    fixed_map = {}
    movable = []
    for i, item_data in enumerate(processed_items):
        is_fixed = False
        if not config.get("shuffle_pos_global", True): is_fixed = True
        if item_data["original_idx"] in fixed_pos_set: is_fixed = True
        if fix_group_pos and item_data["type"] == "cluster": is_fixed = True
        if is_fixed: fixed_map[i] = item_data
        else: movable.append(item_data)
    random.shuffle(movable)
    final_blocks = intro.copy()
    final_keys = []
    movable_idx = 0
    total_items = len(processed_items)
    final_item_list = []
    for i in range(total_items):
        if i in fixed_map: final_item_list.append(fixed_map[i])
        else:
            final_item_list.append(movable[movable_idx])
            movable_idx += 1
    
    q_counter = 0
    def flush_q_group(group, p_type):
        if not group: return []
        if p_type == "PHAN1":
            relabel_mcq_options(group)
            return format_mcq_layout(group)
        elif p_type == "PHAN2":
            relabel_tf_options(group)
            return group
        return group

    for item in final_item_list:
        final_keys.extend(item["keys"])
        if item["type"] == "question":
            q_blocks = item["blocks"]
            if q_blocks:
                q_counter += 1
                update_question_label(q_blocks[0], f"C√¢u {q_counter}.")
                formatted_blocks = flush_q_group(q_blocks, part_type)
                final_blocks.extend(formatted_blocks)
        elif item["type"] == "cluster":
            c_blocks = item["blocks"]
            current_sub_q = []
            for blk in c_blocks:
                txt = get_text(blk)
                if re.match(r'^C√¢u\s*\d+\b', txt):
                    if current_sub_q:
                        final_blocks.extend(flush_q_group(current_sub_q, part_type))
                        current_sub_q = []
                    q_counter += 1
                    update_question_label(blk, f"C√¢u {q_counter}.")
                    current_sub_q.append(blk)
                else:
                    if current_sub_q: current_sub_q.append(blk)
                    else: final_blocks.append(blk)
            if current_sub_q: final_blocks.extend(flush_q_group(current_sub_q, part_type))
    return final_blocks, final_keys

def shuffle_docx_logic(file_bytes, shuffle_mode, header_info, ma_de_str="", config=None):
    if config is None: config = {}
    input_buffer = io.BytesIO(file_bytes)
    keys_by_part = {}
    with zipfile.ZipFile(input_buffer, 'r') as zin:
        doc_xml = zin.read("word/document.xml").decode('utf-8')
        dom = minidom.parseString(doc_xml)
        
        # --- AUTO FIX: T√°ch c√°c ƒë√°p √°n d√≠nh li·ªÅn tr∆∞·ªõc khi tr·ªôn ---
        fix_merged_options(dom)
        
        body = dom.getElementsByTagNameNS(W_NS, "body")[0]
        blocks = []
        other_nodes = []
        for child in list(body.childNodes):
            if child.nodeType == child.ELEMENT_NODE and child.localName in ["p", "tbl"]: blocks.append(child)
            elif child.nodeType == child.ELEMENT_NODE: other_nodes.append(child)
            body.removeChild(child)
        new_blocks = []
        p1 = find_part_index(blocks, 1)
        p2 = find_part_index(blocks, 2)
        p3 = find_part_index(blocks, 3)
        if shuffle_mode != "auto" or (p1 == -1 and p2 == -1 and p3 == -1):
            p_type = "PHAN1" if shuffle_mode == "mcq" or shuffle_mode == "auto" else "PHAN2"
            nb, k = process_part(blocks, 0, len(blocks), p_type, 0, config)
            new_blocks = nb
            keys_by_part['MCQ_ALL' if p_type == "PHAN1" else 'TF_ALL'] = k
        else:
            cursor = 0
            current_global_q_idx = 0 
            if p1 >= 0:
                new_blocks.extend(blocks[cursor:p1+1])
                cursor = p1 + 1
                end1 = p2 if p2 >= 0 else len(blocks)
                nb, k = process_part(blocks, cursor, end1, "PHAN1", current_global_q_idx, config)
                new_blocks.extend(nb)
                keys_by_part['PHAN1'] = k
                current_global_q_idx += len(k)
                cursor = end1
            if p2 >= 0:
                new_blocks.append(blocks[p2])
                cursor = p2 + 1
                end2 = p3 if p3 >= 0 else len(blocks)
                nb, k = process_part(blocks, cursor, end2, "PHAN2", current_global_q_idx, config)
                new_blocks.extend(nb)
                keys_by_part['PHAN2'] = k
                current_global_q_idx += len(k)
                cursor = end2
            if p3 >= 0:
                new_blocks.append(blocks[p3])
                cursor = p3 + 1
                nb, k = process_part(blocks, cursor, len(blocks), "PHAN3", current_global_q_idx, config)
                new_blocks.extend(nb)
                keys_by_part['PHAN3'] = k

        if ma_de_str:
            p_ma = dom.createElementNS(W_NS, "w:p")
            p_ma_pr = dom.createElementNS(W_NS, "w:pPr")
            jc = dom.createElementNS(W_NS, "w:jc")
            jc.setAttributeNS(W_NS, "w:val", "right")
            p_ma_pr.appendChild(jc)
            p_ma.appendChild(p_ma_pr)
            r = dom.createElementNS(W_NS, "w:r")
            t = dom.createElementNS(W_NS, "w:t")
            rPr = dom.createElementNS(W_NS, "w:rPr")
            b = dom.createElementNS(W_NS, "w:b")
            rPr.appendChild(b)
            r.appendChild(rPr)
            t.appendChild(dom.createTextNode(f"M√£ ƒë·ªÅ: {ma_de_str}"))
            r.appendChild(t)
            p_ma.appendChild(r)
            add_header_to_body(dom, body, header_info)
            if header_info.get("enable"):
                if body.childNodes.length > 1: body.insertBefore(p_ma, body.childNodes[1])
                else: body.appendChild(p_ma)
            else:
                if body.firstChild: body.insertBefore(p_ma, body.firstChild)
                else: body.appendChild(p_ma)
        else:
            add_header_to_body(dom, body, header_info)

        footer_rel_id = "rIdFooterNew"
        footer_fname = "word/footer_new.xml"
        sectPrs = body.getElementsByTagNameNS(W_NS, "sectPr")
        if sectPrs: sectPr = sectPrs[-1]
        else:
            sectPr = dom.createElementNS(W_NS, "w:sectPr")
            body.appendChild(sectPr)
        for child in list(sectPr.childNodes):
            if child.localName == "footerReference": sectPr.removeChild(child)
        fr = dom.createElementNS(W_NS, "w:footerReference")
        fr.setAttributeNS(W_NS, "w:type", "default")
        fr.setAttributeNS(R_NS, "r:id", footer_rel_id)
        sectPr.appendChild(fr)

        for b in new_blocks: body.appendChild(b)
        for n in other_nodes: body.appendChild(n)
        
        output_buffer = io.BytesIO()
        with zipfile.ZipFile(output_buffer, 'w', zipfile.ZIP_DEFLATED) as zout:
            footer_xml = create_footer_xml_content(ma_de_str)
            zout.writestr(footer_fname, footer_xml.encode('utf-8'))
            for item in zin.infolist():
                if item.filename == "word/document.xml":
                    zout.writestr(item, dom.toxml().encode('utf-8'))
                elif item.filename == "[Content_Types].xml":
                    ct_xml = zin.read(item).decode('utf-8')
                    ct_dom = minidom.parseString(ct_xml)
                    types = ct_dom.getElementsByTagName("Types")[0]
                    ov = ct_dom.createElement("Override")
                    ov.setAttribute("PartName", "/word/footer_new.xml")
                    ov.setAttribute("ContentType", "application/vnd.openxmlformats-officedocument.wordprocessingml.footer+xml")
                    types.appendChild(ov)
                    zout.writestr(item, ct_dom.toxml().encode('utf-8'))
                elif item.filename == "word/_rels/document.xml.rels":
                    rels_xml = zin.read(item).decode('utf-8')
                    rels_dom = minidom.parseString(rels_xml)
                    relationships = rels_dom.getElementsByTagName("Relationships")[0]
                    rel = rels_dom.createElement("Relationship")
                    rel.setAttribute("Id", footer_rel_id)
                    rel.setAttribute("Type", "http://schemas.openxmlformats.org/officeDocument/2006/relationships/footer")
                    rel.setAttribute("Target", "footer_new.xml")
                    relationships.appendChild(rel)
                    zout.writestr(item, rels_dom.toxml().encode('utf-8'))
                else:
                    zout.writestr(item, zin.read(item.filename))
        return output_buffer.getvalue(), keys_by_part

def generate_real_excel_xlsx(all_answers_dict):
    ma_des = sorted(list(all_answers_dict.keys()))
    if not ma_des: return b""
    headers = ["ƒê·ªÅ \\ C√¢u"]
    headers.extend([str(i) for i in range(1, 41)])
    for q in range(1, 9):
        for char in ['a', 'b', 'c', 'd']: headers.append(f"{q}{char}")
    headers.extend([str(i) for i in range(1, 7)])
    rows_data = []
    for md in ma_des:
        row = [str(md)]
        keys = all_answers_dict[md]
        mcq_list = []
        if 'PHAN1' in keys: mcq_list = keys['PHAN1']
        elif 'MCQ_ALL' in keys: mcq_list = keys['MCQ_ALL']
        row.extend((mcq_list + [""] * 40)[:40])
        tf_data = []
        if 'PHAN2' in keys: tf_data = keys['PHAN2']
        elif 'TF_ALL' in keys: tf_data = keys['TF_ALL']
        tf_flat = []
        for i in range(8):
            if i < len(tf_data): tf_flat.extend((tf_data[i] + [""] * 4)[:4])
            else: tf_flat.extend(["", "", "", ""])
        row.extend(tf_flat)
        sa_list = []
        if 'PHAN3' in keys: sa_list = keys['PHAN3']
        row.extend((sa_list + [""] * 6)[:6])
        rows_data.append(row)
    
    df = pd.DataFrame(rows_data, columns=headers)
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Sheet1')
    return output.getvalue()

def create_summary_table_xml(all_answers_dict):
    ma_des = sorted(list(all_answers_dict.keys()))
    if not ma_des: return None
    mcq_keys_map = {}
    tf_keys_map = {}
    sa_keys_map = {}
    for md in ma_des:
        k = all_answers_dict[md]
        if 'PHAN1' in k: mcq_keys_map[md] = k['PHAN1']
        elif 'MCQ_ALL' in k: mcq_keys_map[md] = k['MCQ_ALL']
        if 'PHAN2' in k: tf_keys_map[md] = k['PHAN2']
        elif 'TF_ALL' in k: tf_keys_map[md] = k['TF_ALL']
        if 'PHAN3' in k: sa_keys_map[md] = k['PHAN3']
    def make_p(text, bold=False, align='center', size=None):
        sz_tag = f'<w:sz w:val="{size}"/>' if size else ''
        b_tag = '<w:b/>' if bold else ''
        safe_text = str(text).replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
        return f'<w:p><w:pPr><w:jc w:val="{align}"/></w:pPr><w:r><w:rPr>{b_tag}{sz_tag}</w:rPr><w:t>{safe_text}</w:t></w:r></w:p>'
    def make_tc(content, width=None):
        w_tag = f'<w:tcW w:w="{width}" w:type="dxa"/>' if width else '<w:tcW w:w="0" w:type="auto"/>'
        return f'<w:tc><w:tcPr>{w_tag}</w:tcPr>{content}</w:tc>'
    body_content = ""
    if mcq_keys_map:
        num_mcq = len(mcq_keys_map[ma_des[0]])
        body_content += make_p("PH·∫¶N I: TR·∫ÆC NGHI·ªÜM", bold=True, align='left', size='28')
        row_cells = make_tc(make_p("C√¢u \\ M√£", bold=True), width=1200)
        for md in ma_des: row_cells += make_tc(make_p(str(md), bold=True), width=800)
        tbl1_rows = f'<w:tr>{row_cells}</w:tr>'
        for i in range(num_mcq):
            row_cells = make_tc(make_p(str(i+1), bold=True))
            for md in ma_des:
                ans = mcq_keys_map[md][i] if i < len(mcq_keys_map[md]) else ""
                row_cells += make_tc(make_p(ans))
            tbl1_rows += f'<w:tr>{row_cells}</w:tr>'
        body_content += f'<w:tbl><w:tblPr><w:tblStyle w:val="TableGrid"/><w:tblW w:w="0" w:type="auto"/><w:tblBorders><w:top w:val="single" w:sz="4"/><w:left w:val="single" w:sz="4"/><w:bottom w:val="single" w:sz="4"/><w:right w:val="single" w:sz="4"/><w:insideH w:val="single" w:sz="4"/><w:insideV w:val="single" w:sz="4"/></w:tblBorders></w:tblPr>{tbl1_rows}</w:tbl><w:p/>'
    if tf_keys_map:
        body_content += make_p("PH·∫¶N II: ƒê√öNG SAI", bold=True, align='left', size='28')
        row_cells = ""
        headers = ["M√£ ƒë·ªÅ", "C√¢u", "√ù a", "√ù b", "√ù c", "√ù d"]
        widths = [1000, 800, 800, 800, 800, 800]
        for idx, h in enumerate(headers): row_cells += make_tc(make_p(h, bold=True), width=widths[idx])
        tbl2_rows = f'<w:tr>{row_cells}</w:tr>'
        for md in ma_des:
            tf_data = tf_keys_map[md]
            for i, ans_list in enumerate(tf_data):
                md_text = str(md)
                row_cells = make_tc(make_p(md_text)) + make_tc(make_p(str(i+1), bold=True))
                for char_idx in range(4):
                    val = ans_list[char_idx] if char_idx < len(ans_list) else ""
                    row_cells += make_tc(make_p(val))
                tbl2_rows += f'<w:tr>{row_cells}</w:tr>'
        body_content += f'<w:tbl><w:tblPr><w:tblStyle w:val="TableGrid"/><w:tblW w:w="0" w:type="auto"/><w:tblBorders><w:top w:val="single" w:sz="4"/><w:left w:val="single" w:sz="4"/><w:bottom w:val="single" w:sz="4"/><w:right w:val="single" w:sz="4"/><w:insideH w:val="single" w:sz="4"/><w:insideV w:val="single" w:sz="4"/></w:tblBorders></w:tblPr>{tbl2_rows}</w:tbl><w:p/>'
    if sa_keys_map:
        body_content += make_p("PH·∫¶N III: TR·∫¢ L·ªúI NG·∫ÆN", bold=True, align='left', size='28')
        row_cells = make_tc(make_p("C√¢u \\ M√£", bold=True), width=1200)
        for md in ma_des: row_cells += make_tc(make_p(str(md), bold=True), width=1500)
        tbl3_rows = f'<w:tr>{row_cells}</w:tr>'
        num_sa = len(sa_keys_map[ma_des[0]])
        for i in range(num_sa):
            row_cells = make_tc(make_p(str(i+1), bold=True))
            for md in ma_des:
                ans = sa_keys_map[md][i] if i < len(sa_keys_map[md]) else ""
                row_cells += make_tc(make_p(ans))
            tbl3_rows += f'<w:tr>{row_cells}</w:tr>'
        body_content += f'<w:tbl><w:tblPr><w:tblStyle w:val="TableGrid"/><w:tblW w:w="0" w:type="auto"/><w:tblBorders><w:top w:val="single" w:sz="4"/><w:left w:val="single" w:sz="4"/><w:bottom w:val="single" w:sz="4"/><w:right w:val="single" w:sz="4"/><w:insideH w:val="single" w:sz="4"/><w:insideV w:val="single" w:sz="4"/></w:tblBorders></w:tblPr>{tbl3_rows}</w:tbl>'
    doc_xml = f"""<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
    <w:document xmlns:w="{W_NS}">
        <w:body>
            <w:p><w:pPr><w:jc w:val="center"/><w:pStyle w:val="Heading1"/></w:pPr><w:r><w:rPr><w:b/><w:sz w:val="32"/></w:rPr><w:t>B·∫¢NG ƒê√ÅP √ÅN T·ªîNG H·ª¢P</w:t></w:r></w:p>
            {body_content}
        </w:body>
    </w:document>
    """
    return doc_xml

def generate_summary_docx(file_bytes, all_answers_dict):
    input_buffer = io.BytesIO(file_bytes)
    output_buffer = io.BytesIO()
    table_xml_str = create_summary_table_xml(all_answers_dict)
    if not table_xml_str: return io.BytesIO(b"") 
    with zipfile.ZipFile(input_buffer, 'r') as zin:
        with zipfile.ZipFile(output_buffer, 'w', zipfile.ZIP_DEFLATED) as zout:
            for item in zin.infolist():
                if item.filename == "word/document.xml":
                    zout.writestr(item, table_xml_str.encode('utf-8'))
                else:
                    zout.writestr(item, zin.read(item.filename))
    return output_buffer.getvalue()


# ==================== PH·∫¶N 2: GIAO DI·ªÜN WEB (STREAMLIT) ====================

st.set_page_config(page_title="Tr·ªôn ƒê·ªÅ Word Pro - AIOMT Online", layout="wide", page_icon="üìö")

# --- HEADER & AUTHOR INFO ---
st.title("üéì H·ªÜ TH·ªêNG TR·ªòN ƒê·ªÄ TR·∫ÆC NGHI·ªÜM TH√îNG MINH")
st.markdown("### üöÄ Gi·∫£i ph√°p tr·ªôn ƒë·ªÅ Word chuy√™n nghi·ªáp")

col_info, col_link = st.columns([2, 1])

with col_info:
    st.markdown("""   
    **üë§ T√°c gi·∫£:** Nguy·ªÖn Th·ªã Thanh V√¢n   
    
    **üì± Zalo:** 0972.777.872     
    
    **üè´ ƒê∆°n v·ªã:** Tr∆∞·ªùng THCS T√¢y Ph√∫       
   
    """)

with col_link:
    st.link_button("üì• T·∫£i ƒê·ªÅ M·∫´u Chu·∫©n (Word)", "https://docs.google.com/document/d/1lCSNGQgulPxcuu3QDEk24pDMPjahXDR_/edit?usp=sharing&ouid=102049743266128652284&rtpof=true&sd=true", help="B·∫•m ƒë·ªÉ xem v√† t·∫£i file m·∫´u ƒë·ªãnh d·∫°ng chu·∫©n")

st.markdown("---")

# --- SIDEBAR CONFIG ---
with st.sidebar:
    st.header("‚öôÔ∏è C·∫•u H√¨nh")
    
    st.subheader("1. Th√¥ng tin Ti√™u ƒë·ªÅ (Header)")
    use_header = st.checkbox("Th√™m b·∫£ng ti√™u ƒë·ªÅ", value=True)
    so_gd = st.text_input("X√£ (S·ªüGD&ƒêT)", "UBND X√É T√ÇY PH√ö", disabled=not use_header)
    truong = st.text_input("Tr∆∞·ªùng", "TR∆Ø·ªúNG THCS T√ÇY PH√ö", disabled=not use_header)
    ky_thi = st.text_input("K·ª≥ Thi", "ƒê·ªÄ KI·ªÇM TRA CU·ªêI K·ª≤ I", disabled=not use_header)
    mon_thi = st.text_input("M√¥n Thi", "TO√ÅN 9", disabled=not use_header)
    thoi_gian = st.text_input("Th·ªùi gian", "90 ph√∫t", disabled=not use_header)
    nam_hoc = st.text_input("NƒÉm h·ªçc", "2025 - 2026", disabled=not use_header)

    st.subheader("2. T√πy ch·ªçn Tr·ªôn")
    shuffle_pos = st.checkbox("Tr·ªôn v·ªã tr√≠ C√¢u h·ªèi", value=True)
    shuffle_opt = st.checkbox("Tr·ªôn v·ªã tr√≠ ƒê√°p √°n (A,B,C,D)", value=True)
    fix_group_pos = st.checkbox("C·ªë ƒë·ªãnh nh√≥m c√¢u h·ªèi d√πng chung", value=True)

    st.subheader("3. M√£ ƒë·ªÅ")
    ma_de_mode = st.radio("C√°ch t·∫°o m√£ ƒë·ªÅ:", ["T·ª± ƒë·ªông (Ng·∫´u nhi√™n)", "T·ª± nh·∫≠p"], index=0)
    
    ma_de_list = []
    if ma_de_mode == "T·ª± ƒë·ªông (Ng·∫´u nhi√™n)":
        num_ver = st.number_input("S·ªë l∆∞·ª£ng ƒë·ªÅ mu·ªën t·∫°o:", min_value=1, max_value=50, value=4)
        start_code = 101
        ma_de_list = [str(start_code + i) for i in range(num_ver)]
    else:
        manual_str = st.text_input("Nh·∫≠p m√£ ƒë·ªÅ (c√°ch nhau d·∫•u ph·∫©y):", "101, 102, 103")
        if manual_str:
            ma_de_list = [s.strip() for s in manual_str.split(',') if s.strip()]

    st.subheader("4. C·ªë ƒë·ªãnh (N√¢ng cao)")
    fixed_pos_str = st.text_input("C√¢u h·ªèi KH√îNG tr·ªôn v·ªã tr√≠ (VD: 1, 40):")
    fixed_opt_str = st.text_input("C√¢u h·ªèi KH√îNG tr·ªôn ƒë√°p √°n (VD: 1-5):")

# --- MAIN CONTENT ---

uploaded_file = st.file_uploader("üìÇ Ch·ªçn file Word (.docx) ƒë·ªÅ g·ªëc", type=["docx"])

if uploaded_file is not None:
    st.success(f"ƒê√£ t·∫£i l√™n: {uploaded_file.name}")
    
    # --- CHECK BUTTON ---
    col_check, col_run = st.columns([1, 1])
    
    with col_check:
        if st.button("üîç KI·ªÇM TRA C·∫§U TR√öC ƒê·ªÄ", type="secondary", use_container_width=True):
            with st.spinner("ƒêang ph√¢n t√≠ch c·∫•u tr√∫c ƒë·ªÅ..."):
                is_valid, messages = check_exam_structure(uploaded_file.getvalue())
                if is_valid and not messages:
                    st.success("‚úÖ ƒê·ªÄ B·∫†N CHU·∫®N! H√£y ti·∫øn h√†nh tr·ªôn ƒë·ªÅ.")
                elif is_valid and messages:
                    # Check if auto-fix happened
                    if any("ƒê√£ t·ª± ƒë·ªông t√°ch" in msg for msg in messages):
                        st.success("‚úÖ ƒê√£ t·ª± ƒë·ªông s·ª≠a l·ªói ƒë·ªãnh d·∫°ng! ƒê·ªÅ b√¢y gi·ªù ƒë√£ h·ª£p l·ªá.")
                        for msg in messages:
                            st.write(msg)
                    else:
                        st.warning("‚ö†Ô∏è ƒê·ªÅ c√≥ th·ªÉ tr·ªôn ƒë∆∞·ª£c, nh∆∞ng c√≥ m·ªôt s·ªë l∆∞u √Ω:")
                        for msg in messages:
                            st.write(msg)
                else:
                    st.error("‚ùå PH√ÅT HI·ªÜN L·ªñI C·∫§U TR√öC (Ph·∫ßn 1):")
                    for msg in messages:
                        st.write(msg)
                    st.info("üí° G·ª£i √Ω: H√£y s·ª≠a l·∫°i c√°c l·ªói tr√™n trong file Word r·ªìi t·∫£i l√™n l·∫°i.")

    with col_run:
        if st.button("üöÄ B·∫ÆT ƒê·∫¶U TR·ªòN ƒê·ªÄ", type="primary", use_container_width=True):
            with st.spinner("ƒêang x·ª≠ l√Ω tr·ªôn ƒë·ªÅ..."):
                try:
                    # ƒê·ªçc file upload
                    file_bytes = uploaded_file.getvalue()
                    
                    # C·∫•u h√¨nh
                    header_info = {
                        "enable": use_header,
                        "so_gd": so_gd, "truong": truong,
                        "ky_thi": ky_thi, "mon_thi": mon_thi,
                        "thoi_gian": thoi_gian, "nam_hoc": nam_hoc
                    }
                    
                    config = {
                        "shuffle_pos_global": shuffle_pos,
                        "shuffle_opt_global": shuffle_opt,
                        "fixed_pos_set": parse_range_string(fixed_pos_str),
                        "fixed_opt_set": parse_range_string(fixed_opt_str),
                        "fix_group_pos": fix_group_pos
                    }
                    
                    all_answers_summary = {}
                    zip_buffer = io.BytesIO()
                    
                    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zout:
                        # Tr·ªôn t·ª´ng ƒë·ªÅ
                        for ma_de in ma_de_list:
                            out_bytes, keys_by_part = shuffle_docx_logic(file_bytes, "auto", header_info, ma_de, config)
                            all_answers_summary[ma_de] = keys_by_part
                            fname = f"De_Tron_Ma_{ma_de}.docx"
                            zout.writestr(fname, out_bytes)
                        
                        # T·∫°o file t·ªïng h·ª£p
                        try:
                            summary_bytes = generate_summary_docx(file_bytes, all_answers_summary)
                            zout.writestr("Dap_an_tong_hop.docx", summary_bytes)
                        except Exception as e:
                            st.error(f"L·ªói t·∫°o file Word ƒë√°p √°n: {e}")

                        try:
                            excel_bytes = generate_real_excel_xlsx(all_answers_summary)
                            zout.writestr("Dap_an_Excel_Chuan.xlsx", excel_bytes)
                        except Exception as e:
                            st.error(f"L·ªói t·∫°o file Excel: {e}")
                    
                    # Ho√†n t·∫•t
                    st.success("‚úÖ ƒê√£ tr·ªôn xong! T·∫£i file k·∫øt qu·∫£ b√™n d∆∞·ªõi.")
                    
                    btn = st.download_button(
                        label="üì• T·∫¢I V·ªÄ FILE K·∫æT QU·∫¢ (.ZIP)",
                        data=zip_buffer.getvalue(),
                        file_name="Ket_qua_tron_de.zip",
                        mime="application/zip"
                    )
                    
                except Exception as e:
                    st.error(f"C√≥ l·ªói x·∫£y ra: {str(e)}")
else:
    st.info("üëà Vui l√≤ng t·∫£i l√™n file ƒë·ªÅ g·ªëc (.docx) ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.markdown("""
    **H∆∞·ªõng d·∫´n:**
    1. Chu·∫©n b·ªã file Word ƒë·ªÅ thi tr·∫Øc nghi·ªám theo ƒë·ªãnh d·∫°ng chu·∫©n (Xem file m·∫´u ·ªü tr√™n).
    2. ƒê√°p √°n ƒë√∫ng c·∫ßn ƒë∆∞·ª£c **G·∫°ch ch√¢n** ho·∫∑c **T√¥ ƒë·ªè**.
    3. T·∫£i file l√™n v√† b·∫•m n√∫t **"Ki·ªÉm tra c·∫•u tr√∫c ƒë·ªÅ"** ƒë·ªÉ r√† so√°t l·ªói.
    4. B·∫•m **"B·∫Øt ƒë·∫ßu tr·ªôn ƒë·ªÅ"** ƒë·ªÉ nh·∫≠n k·∫øt qu·∫£.
    """)
